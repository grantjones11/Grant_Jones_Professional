{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression Model for Points, Rebounds, Assists Prediction\n",
    "\n",
    "The following model pulls from the nba schema specifically the player_stats table to individually predict points, rebounds and assists. Expected Points Added (EPA) feature was engineered to give the model more context for the performance of each player and the overall impact on the team per possesion. Active numeric converts the boolean variable 'Active' to a binary value. String variables are dropped, then the sets for predictions are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from sqlalchemy import Engine\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../')))\n",
    "\n",
    "from data.core.db import engine_nba\n",
    "\n",
    "today = f'{str(pd.Timestamp.today().date()).replace(\"-\", \"\")}'\n",
    "\n",
    "with engine_nba.connect() as conn:\n",
    "    preds = pd.read_sql(sql = 'SELECT * FROM nba.player_stats LIMIT 200000', con=conn)\n",
    "    preds = preds.pivot(index=['game_id', 'team_id', 'player_id', 'player_name'], columns='variable', values='value').reset_index()\n",
    "    #player_names_df = pd.read_sql(sql=\"SELECT DISTINCT player_name FROM nba.player_stats\", con=conn)\n",
    "\n",
    "prop_data_df = pd.DataFrame(preds)\n",
    "\n",
    "#convert target variable to numeric\n",
    "prop_data_df['statistics_points'] = pd.to_numeric(prop_data_df['statistics_points'], errors='coerce')\n",
    "prop_data_df['statistics_field_goals_att'] = pd.to_numeric(prop_data_df['statistics_field_goals_att'], errors='coerce')\n",
    "prop_data_df['statistics_field_goals_pct'] = pd.to_numeric(prop_data_df['statistics_field_goals_pct'], errors='coerce')\n",
    "\n",
    "# Expected Points Added calculation by player\n",
    "prop_data_df['EPA'] = (prop_data_df['statistics_points'] - \n",
    "                       2 * prop_data_df['statistics_field_goals_att'] * \n",
    "                       (prop_data_df['statistics_field_goals_pct'] / 100)\n",
    "                       )\n",
    "\n",
    "# drop unnessecary columns\n",
    "#prop_data_df.drop(columns= 'ejected')\n",
    "#Handle categorical variables\n",
    "prop_data_df['active_numeric'] = prop_data_df['active'].apply(lambda x: 1 if str(x).lower() == 'true' else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subesetting data to form response and predictor variables\n",
    "reference_columns = ['player_id', 'game_id', 'team_id', 'player_name']\n",
    "target_columns = ['statistics_points', 'statistics_rebounds', 'statistics_assists']\n",
    "irrelevant_columns = ['active' , 'on_court' , 'first_name' , \n",
    "                      'last_name' , 'name_suffix' , 'fouled_out' , 'jersey_number',\n",
    "                     'reference' , 'sr_id' , 'starter', 'position', 'primary_position',\n",
    "                      'played', 'not_playing_description', 'not_playing_reason',\n",
    "                      'statistics_double_double', 'statistics_triple_double','statistics_minutes']\n",
    "\n",
    "X = prop_data_df.drop(columns = reference_columns + target_columns + irrelevant_columns)\n",
    "X = X.fillna(0)\n",
    "X = X.apply(pd.to_numeric,errors = 'coerce')\n",
    "Y = prop_data_df[target_columns]\n",
    "Y = Y.fillna(0)\n",
    "Y = Y.apply(pd.to_numeric, errors = 'coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, Y_train)\n",
    "\n",
    "predictions_test = rf_model.predict(X_test)\n",
    "predictions_train = rf_model.predict(X_train)\n",
    "\n",
    "\n",
    "# Curate dataframe and display results\n",
    "test_results = pd.DataFrame({\n",
    "    'player_name': prop_data_df.loc[X_test.index, 'player_name'],\n",
    "    'player_id': prop_data_df.loc[X_test.index, 'player_id'],\n",
    "    'game_id': prop_data_df.loc[X_test.index, 'game_id'],\n",
    "    'team_id': prop_data_df.loc[X_test.index, 'team_id'],\n",
    "    'predicted_points': predictions_test[:, 0],\n",
    "    'predicted_rebounds': predictions_test[:, 1],\n",
    "    'predicted_assists': predictions_test[:, 2]\n",
    "})\n",
    "\n",
    "\n",
    "train_results = pd.DataFrame({\n",
    "    'player_name': prop_data_df.loc[X_train.index, 'player_name'],\n",
    "    'player_id': prop_data_df.loc[X_train.index, 'player_id'],\n",
    "    'game_id': prop_data_df.loc[X_train.index, 'game_id'],\n",
    "    'team_id': prop_data_df.loc[X_train.index, 'team_id'],\n",
    "    'predicted_points': predictions_train[:, 0],\n",
    "    'predicted_rebounds': predictions_train[:, 1],\n",
    "    'predicted_assists': predictions_train[:, 2]\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "full_results = pd.concat([test_results, train_results], ignore_index= True)\n",
    "\n",
    "full_results.to_csv('app/grant/EPA_model_results.csv', index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error for testing set: 0.4598075834748157\n",
      "Mean absolute error for training set: 0.1744732370433305\n",
      "R-Squared value for testing set: 0.8243496953274055\n",
      "R-Squared value for training set: 0.9771846053434703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# basic model diagnostics\n",
    "print(f'Mean absolute error for testing set: {mean_absolute_error(Y_test, predictions_test)}')\n",
    "print(f'Mean absolute error for training set: {mean_absolute_error(Y_train, predictions_train)}')\n",
    "print(f'R-Squared value for testing set: {r2_score(Y_test, predictions_test)}')\n",
    "print(f'R-Squared value for training set: {r2_score(Y_train, predictions_train)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absoulte error for tuned training set: 0.5009035606369645\n",
      "Mean absoulte error for tuned testing set: 0.591901461640491\n",
      "R-Squared value for tuned training set: 0.8618244067192314\n",
      "R-Squared value for tuned testing set: 0.7788995010814249\n",
      "Best parameters for prediction: {'max_depth': 18, 'max_features': 12, 'max_leaf_nodes': 88, 'n_estimators': 135}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Model fine tuning to attempt to increase performance\n",
    "parameters = {'n_estimators' : [125, 130, 135],\n",
    "              'max_depth' : [18, 22, 24], \n",
    "              'max_features' : [10, 11, 12],\n",
    "              'max_leaf_nodes' : [86, 88, 90]\n",
    "                }\n",
    "\n",
    "cv_model = RandomForestRegressor()\n",
    "cv_model = GridSearchCV(cv_model, parameters)\n",
    "\n",
    "cv_model.fit(X_train, Y_train)\n",
    "\n",
    "cv_model_prediction_train = cv_model.predict(X_train)\n",
    "cv_model_prediction_test = cv_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Display fine-tuned model diagnostics\n",
    "print(f'Mean absoulte error for tuned training set: {mean_absolute_error(Y_train,cv_model_prediction_train)}')\n",
    "print(f'Mean absoulte error for tuned testing set: {mean_absolute_error(Y_test,cv_model_prediction_test)}')\n",
    "print(f'R-Squared value for tuned training set: {r2_score(Y_train, cv_model_prediction_train)}')\n",
    "print(f'R-Squared value for tuned testing set: {r2_score(Y_test, cv_model_prediction_test)}')\n",
    "print(f'Best parameters for prediction: {cv_model.best_params_}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "The original untuned model outperforms the tuned model with adjusted parameters in terms of both MAE and R^2. Therefore I reccomend basing predictions off the full_results dataframe. Next steps are to creating a baseline model using linear regression to have a way to compare predictions made using the Random Forest Regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine_nba\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m      2\u001b[0m     preds \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSELECT * FROM nba.model_predictions LIMIT 200000\u001b[39m\u001b[38;5;124m'\u001b[39m, con\u001b[38;5;241m=\u001b[39mconn)\n\u001b[0;32m----> 3\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgame_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvariable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      5\u001b[0m preds\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/jupyter_env/lib/python3.11/site-packages/pandas/core/frame.py:9339\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[0;34m(self, columns, index, values)\u001b[0m\n\u001b[1;32m   9332\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9333\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   9334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpivot\u001b[39m(\n\u001b[1;32m   9335\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, columns, index\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default, values\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m   9336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9337\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[0;32m-> 9339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/jupyter_env/lib/python3.11/site-packages/pandas/core/reshape/pivot.py:570\u001b[0m, in \u001b[0;36mpivot\u001b[0;34m(data, columns, index, values)\u001b[0m\n\u001b[1;32m    566\u001b[0m         indexed \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_constructor_sliced(data[values]\u001b[38;5;241m.\u001b[39m_values, index\u001b[38;5;241m=\u001b[39mmultiindex)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"unstack\" of \"DataFrame\" has incompatible type \"Union\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# [List[Any], ExtensionArray, ndarray[Any, Any], Index, Series]\"; expected\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# \"Hashable\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mindexed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_listlike\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    571\u001b[0m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    572\u001b[0m     name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames\n\u001b[1;32m    573\u001b[0m ]\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/envs/jupyter_env/lib/python3.11/site-packages/pandas/core/series.py:4615\u001b[0m, in \u001b[0;36mSeries.unstack\u001b[0;34m(self, level, fill_value, sort)\u001b[0m\n\u001b[1;32m   4570\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4571\u001b[0m \u001b[38;5;124;03mUnstack, also known as pivot, Series with MultiIndex to produce DataFrame.\u001b[39;00m\n\u001b[1;32m   4572\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4611\u001b[0m \u001b[38;5;124;03mb    2    4\u001b[39;00m\n\u001b[1;32m   4612\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4613\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m unstack\n\u001b[0;32m-> 4615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/jupyter_env/lib/python3.11/site-packages/pandas/core/reshape/reshape.py:517\u001b[0m, in \u001b[0;36munstack\u001b[0;34m(obj, level, fill_value, sort)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(obj\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unstack_extension_series(obj, level, fill_value, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m--> 517\u001b[0m unstacker \u001b[38;5;241m=\u001b[39m \u001b[43m_Unstacker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor_expanddim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unstacker\u001b[38;5;241m.\u001b[39mget_result(\n\u001b[1;32m    521\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_values, value_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[1;32m    522\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/jupyter_env/lib/python3.11/site-packages/pandas/core/reshape/reshape.py:154\u001b[0m, in \u001b[0;36m_Unstacker.__init__\u001b[0;34m(self, index, level, constructor, sort)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_cells \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:\n\u001b[1;32m    147\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following operation may generate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cells\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cells \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the resulting pandas object.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m         PerformanceWarning,\n\u001b[1;32m    151\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    152\u001b[0m     )\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_selectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/jupyter_env/lib/python3.11/site-packages/pandas/core/reshape/reshape.py:210\u001b[0m, in \u001b[0;36m_Unstacker._make_selectors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m mask\u001b[38;5;241m.\u001b[39mput(selector, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex contains duplicate entries, cannot reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_index \u001b[38;5;241m=\u001b[39m comp_index\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m mask\n",
      "\u001b[0;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "\n",
    "with engine_nba.connect() as conn:\n",
    "    preds = pd.read_sql(sql = 'SELECT * FROM nba.model_predictions LIMIT 200000', con=conn)\n",
    "    preds = preds.pivot(index='game_id', columns='variable', values='value').reset_index()\n",
    "\n",
    "preds.head(10)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
